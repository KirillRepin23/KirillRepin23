{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "Bk_iz8VriCJm"
      },
      "outputs": [],
      "source": [
        "import re\n",
        "import json\n",
        "import pandas as pd\n",
        "from google.oauth2 import service_account\n",
        "from datetime import date, timedelta, datetime\n",
        "import time as tm\n",
        "import os\n",
        "from dateutil.relativedelta import relativedelta\n",
        "import io\n",
        "import requests"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Здесь нужно добавить id файла json в гугл диске - цифры после id\n",
        "!gdown 'https://drive.google.com/uc?id={id_file}'"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "i_E0nl8jpKI2",
        "outputId": "5e155ad5-58ec-4973-edac-b2989e25f3ff"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Downloading...\n",
            "From: https://drive.google.com/uc?id=1QwmLE2ISnBSukCCL0QdlHgCvZvrUmB0g\n",
            "To: /content/eaptekareklama-bq-ffab31fc6860.json\n",
            "\r  0% 0.00/2.31k [00:00<?, ?B/s]\r100% 2.31k/2.31k [00:00<00:00, 2.26MB/s]\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "API_TOKEN = '____________________________' \n",
        "# В качестве пути указываем путь, показанный в предыдущем шаге\n",
        "credentials = service_account.Credentials.from_service_account_file('/content/eaptekareklama-bq-ffab31fc6860.json')\n",
        "additional_fields = 'device_model'\n",
        "load_date = (date.today()-timedelta(days=1)).strftime('%Y-%m-%d')\n",
        "from_date = (date.today()-timedelta(days=1)-timedelta(days=int((date.today()-timedelta(days=1)).strftime('%d'))-1)).strftime('%Y-%m-%d')\n",
        "from_date_det = (date.today()-timedelta(days=8)).strftime('%Y-%m-%d')"
      ],
      "metadata": {
        "id": "v4DVFmF7ib1s"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "def load_table(app_id, API_TOKEN, additional_fields, load_date):\n",
        "  params = {\n",
        "        'api_token':API_TOKEN, \n",
        "        'additional_fields':additional_fields,\n",
        "        'maximum_rows':'1000000',\n",
        "    }\n",
        "  params['from'] = load_date\n",
        "  params['to'] = load_date\n",
        "  params['event_name'] = 'af_first_order,af_purchase'\n",
        "  s = ''\n",
        "  for key, value in params.items():\n",
        "    d = key + '=' + value + '&'\n",
        "    s += d\n",
        "  df = pd.read_csv(f'https://hq.appsflyer.com/export/{app_id}/in_app_events_report/v5?' + s[:-1], parse_dates = ['Install Time', 'Event Time'])\n",
        "  df_part = df[['Install Time','Event Time', 'Event Name', 'Event Revenue', 'Media Source', 'Campaign', 'AppsFlyer ID', 'Partner']]\n",
        "  df_part.columns = [x.replace(' ', '_').lower() for x in df_part.columns]\n",
        "  df_part['install_date'] = df_part.install_time.dt.date\n",
        "  df_part['event_date'] = df_part.event_time.dt.date\n",
        "  df_agg = df_part.groupby(['install_date', 'event_date', 'campaign', 'event_name', 'media_source', 'partner'], as_index=False) \\\n",
        "                  .agg({'appsflyer_id': 'nunique', 'event_revenue': 'sum'}) \\\n",
        "                  .rename(columns={'appsflyer_id': 'users', 'event_revenue': 'revenue'})\n",
        "  df_agg[['install_date', 'event_date', 'campaign', 'event_name', 'media_source', 'partner']] = df_agg[['install_date', 'event_date', 'campaign', 'event_name', 'media_source', 'partner']].astype('str')\n",
        "  df_agg[['users', 'revenue']] = df_agg[['users', 'revenue']].astype('float')\n",
        "  return df_agg"
      ],
      "metadata": {
        "id": "I9E7uvOqp8xo"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "def load_fraud(app_id, API_TOKEN, report, additional_fields, field, count_field, load_date):\n",
        "  params = {\n",
        "        'api_token':API_TOKEN, \n",
        "        'additional_fields':additional_fields,\n",
        "        'maximum_rows':'1000000',\n",
        "    }\n",
        "  params['from'] = load_date\n",
        "  params['to'] = load_date\n",
        "  s = ''\n",
        "  for key, value in params.items():\n",
        "    d = key + '=' + value + '&'\n",
        "    s += d\n",
        "  df = pd.read_csv(f'https://hq.appsflyer.com/export/{app_id}/{report}/v5?' + s[:-1], parse_dates = ['Event Time'])\n",
        "  df_part = df[['Event Time', 'Event Name', 'Media Source', 'Campaign', 'AppsFlyer ID', 'Partner', field]]\n",
        "  df_part.columns = [x.replace(' ', '_').lower() for x in df_part.columns]\n",
        "  df_part = df_part.query('event_name == \"install\"')\n",
        "  df_part['event_date'] = df_part.event_time.dt.date\n",
        "  df_agg = df_part.groupby(['event_date', 'campaign', 'media_source', 'partner', additional_fields], as_index=False) \\\n",
        "                  .agg({'appsflyer_id': 'nunique'}) \\\n",
        "                  .rename(columns={'appsflyer_id': count_field})\n",
        "  df_agg[['event_date', 'campaign', 'media_source', 'partner', additional_fields]] = df_agg[['event_date', 'campaign', 'media_source', 'partner', additional_fields]].astype('str')\n",
        "  df_agg[count_field] = df_agg[count_field].astype('int')\n",
        "  return df_agg"
      ],
      "metadata": {
        "id": "eh3OCEk5ZItv"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "def load_fraud_detection(app_id, API_TOKEN, from_date_det, load_date):\n",
        "    url = f\"https://hq.appsflyer.com/export/{app_id}/detection/v5?from={from_date_det}&to={load_date}&maximum_rows=1000000&additional_fields=fraud_reasons&api_token={API_TOKEN}\"\n",
        "    headers = {\"accept\": \"text/csv\"}\n",
        "    response = requests.get(url, headers=headers)\n",
        "    df = pd.read_csv(io.StringIO(response.content.decode('utf-8')), parse_dates = ['Event Time'])\n",
        "    df_part = df[['Event Time', 'Event Name', 'Media Source', 'Campaign', 'AppsFlyer ID', 'Partner', 'Fraud Reasons']]\n",
        "    df_part.columns = [x.replace(' ', '_').lower() for x in df_part.columns]\n",
        "    df_part = df_part.query('event_name == \"install\"')\n",
        "    df_part['event_date'] = df_part.event_time.dt.date\n",
        "    df_agg = df_part.groupby(['event_date', 'campaign', 'media_source', 'partner', 'fraud_reasons'], as_index=False) \\\n",
        "                    .agg({'appsflyer_id': 'nunique'}) \\\n",
        "                    .rename(columns={'appsflyer_id': 'count_fraudinst'})\n",
        "    df_agg[['event_date', 'campaign', 'media_source', 'partner', 'fraud_reasons']] = df_agg[['event_date', 'campaign', 'media_source', 'partner', 'fraud_reasons']].astype('str')\n",
        "    df_agg['count_fraudinst'] = df_agg['count_fraudinst'].astype('int')\n",
        "    return df_agg"
      ],
      "metadata": {
        "id": "2l42to6OJSSq"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "def load_users(app_id, from_date, load_date):\n",
        "  url = f\"https://hq1.appsflyer.com/api/cohorts/v1/data/app/{app_id}\"\n",
        "  payload = {\n",
        "      \"kpis\": [\"users\"],\n",
        "      \"groupings\": [\"date\", \"c\", \"af_prt\"],\n",
        "      \"from\": from_date,\n",
        "      \"to\": load_date,\n",
        "      \"min_cohort_size\": 1,\n",
        "      \"aggregation_type\": \"on_day\",\n",
        "      \"cohort_type\": \"user_acquisition\"\n",
        "  }\n",
        "  # Здесь в качестве токена вставляем версию API token V2.0 (который в несколько раз длиннее)\n",
        "  headers = {\n",
        "      \"accept\": \"application/json\",\n",
        "      \"content-type\": \"application/json\",\n",
        "      \"authorization\": \"Bearer ___________________________________________________________________________________________________________\"\n",
        "  }\n",
        "\n",
        "  response = requests.post(url, json=payload, headers=headers)\n",
        "  rawData = pd.read_csv(io.StringIO(response.content.decode('utf-8')))\n",
        "  rawData.date = pd.to_datetime(rawData.date)\n",
        "  df_users = rawData.query('af_prt == \"realweb\"')[['date', 'c', 'users']].rename(columns={'date': 'install_date', 'c': 'campaign'})\n",
        "  return df_users"
      ],
      "metadata": {
        "id": "YVWvn146JJek"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "def cohort_func(df, min_date, event, agg_field, df_users, dict_ag, dict_s):\n",
        "  df_cohort_event = df.query('install_date >= @min_date and event_name == @event')[['install_date', 'campaign', agg_field, 'period']] \\\n",
        "                          .groupby(['install_date', 'campaign', 'period'], as_index=False).agg({agg_field:'sum'})\n",
        "  max_df_period_ev = df_cohort_event.period.max()\n",
        "  df_event_pivot = df_cohort_event.pivot_table(index = ['campaign', 'install_date'],\n",
        "                                      columns = 'period',\n",
        "                                      values = agg_field)\n",
        "  df_event_pivot.columns.name = None\n",
        "  df_event_pivot = df_event_pivot.reset_index().fillna(0) \\\n",
        "                  .rename(columns={i: f'{event} - count - day {i} - partial' for i in range(max_df_period_ev + 1)}) \\\n",
        "                  .merge(df_users, how='right', on=['campaign', 'install_date']).fillna(0) \\\n",
        "                  .rename(columns={'campaign': 'Campaign', 'install_date': 'Cohort Day', 'users': 'Users'}) \\\n",
        "                  .sort_values('Cohort Day')\n",
        "  cols = df_event_pivot.columns.tolist()\n",
        "  df_event_pivot = df_event_pivot[cols[:2] + cols[-1:] + cols[2:-1]]\n",
        "  cols = df_event_pivot.columns.tolist()\n",
        "  for i in range(4,len(cols)):\n",
        "    df_event_pivot[cols[i]] += df_event_pivot[cols[i-1]]\n",
        "  df_event_pivot[cols[3:]] = df_event_pivot[cols[3:]].round().astype('int')\n",
        "  df_event_pivot['Cohort Day'] = df_event_pivot['Cohort Day'].astype('str').apply(lambda x: '.'.join(x.split('-')[::-1]))\n",
        "  df_event_pivot = df_event_pivot.reset_index(drop=True)\n",
        "  df_event_pivot.Campaign = df_event_pivot.Campaign.apply(lambda x: 'xapads_eapteka_a111_c217' if x == 'xapads-eapteka-xm' else x) \\\n",
        "                                                    .apply(lambda x: 'no_name_of_campaign' if len(x.split('_')) < 4 else x)\n",
        "  df_event_pivot['code_agency'] = df_event_pivot.Campaign.apply(lambda x: x.split('_')[2] if len(x.split('_'))>1 and x.split('_')[2].startswith('a') else '')\n",
        "  df_event_pivot['code_source'] = df_event_pivot.Campaign.apply(lambda x: x.split('_')[3] if len(x.split('_'))>1 and x.split('_')[3].startswith('c') else '')\n",
        "  df_cohort_final_ev = df_event_pivot.merge(dict_ag, how='left', on='code_agency') \\\n",
        "                                      .merge(dict_s, how='left', on='code_source') \\\n",
        "                                      .drop(columns=['code_agency', 'code_source'])\n",
        "  cols = df_cohort_final_ev.columns.tolist()\n",
        "  df_cohort_final_ev = df_cohort_final_ev[cols[-1:] + cols[-2:-1] + cols[:-2]]\n",
        "  df_cohort_final_ev.Users = df_cohort_final_ev.Users.fillna(0).astype('int')\n",
        "  return df_cohort_final_ev"
      ],
      "metadata": {
        "id": "SLjDjuuQ8fMG"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "df_load_andr = load_table('ru.getpharma.eapteka', API_TOKEN, additional_fields, load_date)\n",
        "df_load_ios = load_table('id570400364', API_TOKEN, additional_fields, load_date)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "E-qV6Kj8IHii",
        "outputId": "5e96ef9c-7e69-46c6-a94e-3db71dc33b80"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "<ipython-input-49-89b3a1876af9>:17: SettingWithCopyWarning: \n",
            "A value is trying to be set on a copy of a slice from a DataFrame.\n",
            "Try using .loc[row_indexer,col_indexer] = value instead\n",
            "\n",
            "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
            "  df_part['install_date'] = df_part.install_time.dt.date\n",
            "<ipython-input-49-89b3a1876af9>:18: SettingWithCopyWarning: \n",
            "A value is trying to be set on a copy of a slice from a DataFrame.\n",
            "Try using .loc[row_indexer,col_indexer] = value instead\n",
            "\n",
            "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
            "  df_part['event_date'] = df_part.event_time.dt.date\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "sql_and_check = f\"\"\"SELECT * FROM `eaptekareklama-bq.Appsflyer.appsflyer_in_app_events_android`\n",
        "WHERE event_date >= '{from_date}'\"\"\"\n",
        "all_data_android = pd.read_gbq(sql_and_check, credentials=credentials, dialect='standard')\n",
        "sql_ios_check = f\"\"\"SELECT * FROM `eaptekareklama-bq.Appsflyer.appsflyer_in_app_events_ios`\n",
        "WHERE event_date >= '{from_date}'\"\"\"\n",
        "all_data_ios = pd.read_gbq(sql_ios_check, credentials=credentials, dialect='standard')"
      ],
      "metadata": {
        "id": "f5BBFaVwnu-Z"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "if all_data_android.merge(df_load_andr, how='inner', on=df_load_andr.columns.to_list()).shape[0] == 0:\n",
        "    df_load_andr.to_gbq('eaptekareklama-bq.Appsflyer.appsflyer_in_app_events_android', \n",
        "          project_id='eaptekareklama-bq',  \n",
        "          if_exists='append',\n",
        "          credentials=credentials)\n",
        "if all_data_ios.merge(df_load_ios, how='inner', on=df_load_ios.columns.to_list()).shape[0] == 0:\n",
        "    df_load_ios.to_gbq('eaptekareklama-bq.Appsflyer.appsflyer_in_app_events_ios', \n",
        "          project_id='eaptekareklama-bq',  \n",
        "          if_exists='append',\n",
        "          credentials=credentials)"
      ],
      "metadata": {
        "id": "sEmX4vCnnv6Y"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "andr_users = load_users('ru.getpharma.eapteka', from_date, load_date)\n",
        "ios_users = load_users('id570400364', from_date, load_date)"
      ],
      "metadata": {
        "id": "wXu9_X2Wnzhi"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "dict_ag = pd.DataFrame({'code_agency': ['a485', 'a617', 'a564', 'a339', 'a776', 'a999', 'a499', 'a224', 'a823', 'a662', 'a799', 'a391', 'a888', 'a111'], \n",
        "                        'Agency name': ['2leads', 'Borscht', 'Colead', 'GoMobile', 'Gradientt', 'In-house', 'Mediaserfer', 'Mobisharks', 'MobX', 'Rocket10', 'ThinkMobile', 'TopTraffic', 'Mobio', 'xapads']})\n",
        "dict_s = pd.DataFrame({'code_source': ['c201', 'c202', 'c203', 'c204', 'c210', 'c205', 'c206', 'c209', 'c207', 'c208', 'c211', 'c212', 'c217', 'c215', 'с216', 'с218', 'с219'], \n",
        "                        'Source name': ['Apple Search Ads', 'DV360', 'Facebook', 'Google Adwords', 'in-app', 'Mytarget', 'Tik Tok', 'Twitter', 'VK', 'Yandex.Direct', 'Appnext', 'beta vk', 'xapads', 'AdGate', 'Bigo Ads', 'untiy', 'mintegral']})"
      ],
      "metadata": {
        "id": "RuSPl5QQnzsg"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "all_data_android = all_data_android.query('partner == \"realweb\"')\n",
        "all_data_android.event_date = pd.to_datetime(all_data_android.event_date)\n",
        "all_data_android.install_date = pd.to_datetime(all_data_android.install_date)\n",
        "all_data_android['period'] = (all_data_android.event_date - all_data_android.install_date).dt.days\n",
        "# min_date_android = all_data_android.event_date.min()\n",
        "min_date_android = from_date"
      ],
      "metadata": {
        "id": "GtbGQ3QRnzvK"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "andr_cohort_final_ord = cohort_func(all_data_android, min_date_android, 'af_first_order', 'users', andr_users, dict_ag, dict_s)\n",
        "andr_cohort_final_pur = cohort_func(all_data_android, min_date_android, 'af_purchase', 'users', andr_users, dict_ag, dict_s)\n",
        "andr_cohort_final_pur_rev = cohort_func(all_data_android, min_date_android, 'af_purchase', 'revenue', andr_users, dict_ag, dict_s)"
      ],
      "metadata": {
        "id": "HS2QtU7ynzxx"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "all_data_ios = all_data_ios.query('partner == \"realweb\"')\n",
        "all_data_ios.event_date = pd.to_datetime(all_data_ios.event_date)\n",
        "all_data_ios.install_date = pd.to_datetime(all_data_ios.install_date)\n",
        "all_data_ios['period'] = (all_data_ios.event_date - all_data_ios.install_date).dt.days\n",
        "# min_date_ios = all_data_ios.event_date.min()\n",
        "min_date_ios = from_date"
      ],
      "metadata": {
        "id": "YQiVaSxanz0Y"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "ios_cohort_final_ord = cohort_func(all_data_ios, min_date_ios, 'af_first_order', 'users', ios_users, dict_ag, dict_s)\n",
        "ios_cohort_final_pur = cohort_func(all_data_ios, min_date_ios, 'af_purchase', 'users', ios_users, dict_ag, dict_s)\n",
        "ios_cohort_final_pur_rev = cohort_func(all_data_ios, min_date_ios, 'af_purchase', 'revenue', ios_users, dict_ag, dict_s)"
      ],
      "metadata": {
        "id": "ABAy4X0wnz3A"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "from oauth2client.service_account import ServiceAccountCredentials\n",
        "import gspread\n",
        "from gspread_dataframe import set_with_dataframe\n",
        "\n",
        "scope = [\n",
        "    'https://www.googleapis.com/auth/spreadsheets',\n",
        "]\n",
        "\n",
        "GOOGLE_KEY_FILE = '/content/eaptekareklama-bq-ffab31fc6860.json'\n",
        "\n",
        "credentials_spread = ServiceAccountCredentials.from_json_keyfile_name(GOOGLE_KEY_FILE, scope)\n",
        "gc = gspread.authorize(credentials_spread)\n",
        "\n",
        "# Здесь вставляем id файла в спредшите (можно определить по ссылке)\n",
        "workbook_key = '______________________________________________'\n",
        "workbook = gc.open_by_key(workbook_key)"
      ],
      "metadata": {
        "id": "kdeVf-I1nz5q"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "sheet1 = workbook.worksheet('andr_coh_order')\n",
        "sheet1.clear()\n",
        "set_with_dataframe(worksheet=sheet1, dataframe=andr_cohort_final_ord, include_index=False,\n",
        "include_column_header=True, resize=True)\n",
        "sheet2 = workbook.worksheet('andr_coh_pur')\n",
        "sheet2.clear()\n",
        "set_with_dataframe(worksheet=sheet2, dataframe=andr_cohort_final_pur, include_index=False,\n",
        "include_column_header=True, resize=True)\n",
        "sheet3 = workbook.worksheet('andr_coh_pur_rev')\n",
        "sheet3.clear()\n",
        "set_with_dataframe(worksheet=sheet3, dataframe=andr_cohort_final_pur_rev, include_index=False,\n",
        "include_column_header=True, resize=True)\n",
        "sheet4 = workbook.worksheet('ios_coh_order')\n",
        "sheet4.clear()\n",
        "set_with_dataframe(worksheet=sheet4, dataframe=ios_cohort_final_ord, include_index=False,\n",
        "include_column_header=True, resize=True)\n",
        "sheet5 = workbook.worksheet('ios_coh_pur')\n",
        "sheet5.clear()\n",
        "set_with_dataframe(worksheet=sheet5, dataframe=ios_cohort_final_pur, include_index=False,\n",
        "include_column_header=True, resize=True)\n",
        "sheet6 = workbook.worksheet('ios_coh_pur_rev')\n",
        "sheet6.clear()\n",
        "set_with_dataframe(worksheet=sheet6, dataframe=ios_cohort_final_pur_rev, include_index=False,\n",
        "include_column_header=True, resize=True)"
      ],
      "metadata": {
        "id": "RjDPTaeLnz8d"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "df_detection_android = load_fraud_detection('ru.getpharma.eapteka', API_TOKEN, from_date_det, load_date)\n",
        "df_detection_ios = load_fraud_detection('id570400364', API_TOKEN, from_date_det, load_date)"
      ],
      "metadata": {
        "id": "zXRno-yxYHnj"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "sql_block_andr = \"\"\"SELECT * FROM `eaptekareklama-bq.Appsflyer.appsflyer_detection_android`\"\"\"\n",
        "data_block_android = pd.read_gbq(sql_block_andr, credentials=credentials, dialect='standard')\n",
        "data_block_android = data_block_android.drop_duplicates()\n",
        "data_block_android.event_date = pd.to_datetime(data_block_android.event_date)\n",
        "data_det_android = data_block_android.query('event_date < @from_date_det')\n",
        "data_det_android.event_date = data_det_android.event_date.dt.date.astype('str')\n",
        "data_det_and = pd.concat([data_det_android, df_detection_android])\n",
        "sql_block_ios = \"\"\"SELECT * FROM `eaptekareklama-bq.Appsflyer.appsflyer_detection_ios`\"\"\"\n",
        "data_block_ios = pd.read_gbq(sql_block_ios, credentials=credentials, dialect='standard')\n",
        "data_block_ios = data_block_ios.drop_duplicates()\n",
        "data_block_ios.event_date = pd.to_datetime(data_block_ios.event_date)\n",
        "data_det_ios = data_block_ios.query('event_date < @from_date_det')\n",
        "data_det_ios.event_date = data_det_ios.event_date.dt.date.astype('str')\n",
        "data_det_ios_f = pd.concat([data_det_ios, df_detection_ios])"
      ],
      "metadata": {
        "id": "zeEoEU0WpCD3"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "data_det_and.to_gbq('eaptekareklama-bq.Appsflyer.appsflyer_detection_android', \n",
        "          project_id='eaptekareklama-bq',  \n",
        "          if_exists='replace',\n",
        "          credentials=credentials)\n",
        "data_det_ios_f.to_gbq('eaptekareklama-bq.Appsflyer.appsflyer_detection_ios', \n",
        "          project_id='eaptekareklama-bq',  \n",
        "          if_exists='replace',\n",
        "          credentials=credentials)"
      ],
      "metadata": {
        "id": "HyCba5PfpCJB"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "data_block_android = data_block_android.query('partner == \"realweb\"')\n",
        "data_block_ios = data_block_ios.query('partner == \"realweb\"')\n",
        "data_block_android.event_date = pd.to_datetime(data_block_android.event_date)\n",
        "data_block_ios.event_date = pd.to_datetime(data_block_ios.event_date)\n",
        "min_date_android_block = from_date\n",
        "min_date_ios_block = from_date\n",
        "df_block_andr = data_block_android.query('event_date >= @min_date_android_block')[['event_date', 'campaign', 'count_fraudinst']] \\\n",
        "                          .groupby(['event_date', 'campaign'], as_index=False).agg({'count_fraudinst':'sum'})\n",
        "df_block_ios = data_block_ios.query('event_date >= @min_date_ios_block')[['event_date', 'campaign', 'count_fraudinst']] \\\n",
        "                          .groupby(['event_date', 'campaign'], as_index=False).agg({'count_fraudinst':'sum'})\n",
        "df_block_andr['code_agency'] = df_block_andr.campaign.apply(lambda x: x.split('_')[2] if len(x.split('_'))>1 and x.split('_')[2].startswith('a') else '')\n",
        "df_block_andr['code_source'] = df_block_andr.campaign.apply(lambda x: x.split('_')[3] if len(x.split('_'))>1 and x.split('_')[3].startswith('c') else '')\n",
        "df_block_ios['code_agency'] = df_block_ios.campaign.apply(lambda x: x.split('_')[2] if len(x.split('_'))>1 and x.split('_')[2].startswith('a') else '')\n",
        "df_block_ios['code_source'] = df_block_ios.campaign.apply(lambda x: x.split('_')[3] if len(x.split('_'))>1 and x.split('_')[3].startswith('c') else '')\n",
        "andr_final_block = df_block_andr.merge(dict_ag, how='left', on='code_agency') \\\n",
        "                                .merge(dict_s, how='left', on='code_source') \\\n",
        "                                .drop(columns=['code_agency', 'code_source'])\n",
        "andr_final_block = andr_final_block[['Source name', 'Agency name', 'campaign', 'event_date', 'count_fraudinst']]\n",
        "andr_final_block.event_date = andr_final_block.event_date.dt.date\n",
        "ios_final_block = df_block_ios.merge(dict_ag, how='left', on='code_agency') \\\n",
        "                              .merge(dict_s, how='left', on='code_source') \\\n",
        "                              .drop(columns=['code_agency', 'code_source'])\n",
        "ios_final_block = ios_final_block[['Source name', 'Agency name', 'campaign', 'event_date', 'count_fraudinst']]\n",
        "ios_final_block.event_date = ios_final_block.event_date.dt.date"
      ],
      "metadata": {
        "id": "k2d2ATfMpCLY"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "sheet7 = workbook.worksheet('Protect_and_install')\n",
        "sheet7.clear()\n",
        "set_with_dataframe(worksheet=sheet7, dataframe=andr_final_block, include_index=False,\n",
        "include_column_header=True, resize=True)\n",
        "sheet8 = workbook.worksheet('Protect_iOS_install')\n",
        "sheet8.clear()\n",
        "set_with_dataframe(worksheet=sheet8, dataframe=ios_final_block, include_index=False,\n",
        "include_column_header=True, resize=True)"
      ],
      "metadata": {
        "id": "KTvKzD1OpCNw"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "AdgAvkfGpCQG"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "cGMdrgBKpCSh"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "crVY6li-pCU5"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "FMXi2tJupCXK"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "RgeFl87kpCZu"
      },
      "execution_count": null,
      "outputs": []
    }
  ]
}